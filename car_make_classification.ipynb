{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA6tBwjEa1aN"
      },
      "source": [
        "# Car Make Classification using Inception-v4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxQeYWac9MRI",
        "outputId": "5bc1f917-417d-4244-877c-c4e4f2de35a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiT0mmX3CbBl",
        "outputId": "088cde77-2de1-4c6a-af37-753f1daab8d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Car-make-classification'...\n",
            "remote: Enumerating objects: 102680, done.\u001b[K\n",
            "remote: Counting objects: 100% (2938/2938), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2934/2934), done.\u001b[K\n",
            "remote: Total 102680 (delta 9), reused 18 (delta 4), pack-reused 99742 (from 1)\u001b[K\n",
            "Receiving objects: 100% (102680/102680), 981.55 MiB | 54.36 MiB/s, done.\n",
            "Resolving deltas: 100% (6850/6850), done.\n",
            "Updating files: 100% (33622/33622), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/pedermae/Car-make-classification.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-WbU46ROx9b",
        "outputId": "550e0346-9874-4456-a170-89dc1ad7829e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Car-make-classification\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Car-make-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HfE0G9mN8rgO"
      },
      "outputs": [],
      "source": [
        "# Import dependencies\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from torchvision.transforms import Compose, ToTensor, RandomAffine, RandomHorizontalFlip, RandomVerticalFlip\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import Module, Sequential, Conv2d, BatchNorm2d, ReLU, MaxPool2d, AvgPool2d, Linear, Dropout, CrossEntropyLoss\n",
        "from torch.optim import SGD, Adam\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hxxxj5q0aPmD"
      },
      "outputs": [],
      "source": [
        "#import sys\n",
        "#sys.path.insert(0,'/content/drive/MyDrive/Colab Notebooks/modules')\n",
        "from dataset import ImageDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OqOq4BsP8rgU"
      },
      "outputs": [],
      "source": [
        "#Securing reproducability\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XISH9-Hc8rgV"
      },
      "outputs": [],
      "source": [
        "transforms = Compose([\n",
        "    ToTensor(), #this converts numpy or Pil image to torch tensor and normalizes it in 0, 1\n",
        "    RandomAffine((0.05, 0.05)),\n",
        "    RandomHorizontalFlip(),\n",
        "    RandomVerticalFlip()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jHpZpML8rgd"
      },
      "source": [
        "## Building Inception-v4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ehGORqEw8rge"
      },
      "outputs": [],
      "source": [
        "class Conv2d_bn(Module):\n",
        "    def __init__(self, in_filters, out_filters, kernel_size, strides, padding):\n",
        "        super().__init__()\n",
        "        if isinstance(kernel_size, tuple):\n",
        "            padding_val = (k // 2 for k in kernel_size) if padding == \"same\" else (0,0)\n",
        "        else:\n",
        "            padding_val = kernel_size // 2 if padding == \"same\" else 0\n",
        "        self.conv = Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride=strides, padding=padding_val)\n",
        "        self.bn = BatchNorm2d(out_filters)\n",
        "        self.relu = ReLU()\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.bn(self.conv(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "X2l1R1Ly8rge"
      },
      "outputs": [],
      "source": [
        "class StemBlock(Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.first_block = Sequential(\n",
        "            Conv2d_bn(in_filters=3, out_filters=32, kernel_size=3, strides=2, padding=\"valid\"),\n",
        "            Conv2d_bn(in_filters=32, out_filters=32, kernel_size=3, strides=1, padding=\"valid\"),\n",
        "            Conv2d_bn(in_filters=32, out_filters=64, kernel_size=3, strides=1, padding=\"same\"),\n",
        "        )\n",
        "        self.first_left = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "        self.first_right = Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=2, padding=\"valid\")\n",
        "        self.second_left =  Sequential(\n",
        "            Conv2d_bn(in_filters=160, out_filters=64, kernel_size=1, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding=\"valid\"),\n",
        "        )\n",
        "        self.second_right =  Sequential(\n",
        "            Conv2d_bn(in_filters=160, out_filters=64, kernel_size=1, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=64, out_filters=64, kernel_size=(7, 1), strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=64, out_filters=64, kernel_size=(1, 7), strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding=\"valid\"),\n",
        "        )\n",
        "        self.third_left = Conv2d_bn(in_filters=192, out_filters=192, kernel_size=3, strides=2, padding=\"valid\")\n",
        "        self.third_right = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.first_block(x)\n",
        "        x_l = self.first_left(x)\n",
        "        x_r = self.first_right(x)\n",
        "        x = torch.cat([x_l, x_r], axis=1)\n",
        "        x_l = self.second_left(x)\n",
        "        x_r = self.second_right(x)\n",
        "        x = torch.cat([x_l, x_r], axis=1)\n",
        "        x_l = self.third_left(x)\n",
        "        x_r = self.third_right(x)\n",
        "        x = torch.cat([x_l, x_r], axis=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CaiYYV1d8rgf"
      },
      "outputs": [],
      "source": [
        "class A_block(Module):\n",
        "\n",
        "    def __init__(self, in_filters):\n",
        "        super().__init__()\n",
        "        self.avg_block = Sequential(\n",
        "            AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=96, kernel_size=1, strides=1, padding=\"same\"),\n",
        "        )\n",
        "        self.one_by_one_block = Conv2d_bn(in_filters=in_filters, out_filters=96, kernel_size=1, strides=1, padding=\"same\")\n",
        "        self.three_by_three_block =  Sequential(\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=64, kernel_size=1, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding=\"same\"),\n",
        "        )\n",
        "        self.five_by_five =  Sequential(\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=64, kernel_size=1, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=96, out_filters=96, kernel_size=3, strides=1, padding=\"same\"),\n",
        "        )\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "    def forward(self, x):\n",
        "        x_1 = self.avg_block(x)\n",
        "        x_2 = self.one_by_one_block(x)\n",
        "        x_3 = self.three_by_three_block(x)\n",
        "        x_4 = self.five_by_five(x)\n",
        "        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7ZCc9W5g8rgg"
      },
      "outputs": [],
      "source": [
        "class B_block(Module):\n",
        "\n",
        "    def __init__(self, in_filters):\n",
        "        super().__init__()\n",
        "        self.avg_block = Sequential(\n",
        "            AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=128, kernel_size=1, strides=1, padding=\"same\"),\n",
        "        )\n",
        "        self.one_by_one_block = Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=1, strides=1, padding=\"same\")\n",
        "\n",
        "        self.seven_by_seven_block =  Sequential(\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=192, out_filters=224, kernel_size=(1, 7), strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=224, out_filters=256, kernel_size=(7, 1), strides=1, padding=\"same\"),\n",
        "        )\n",
        "\n",
        "        self.thirteen_by_thirteen_block =  Sequential(\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=192, out_filters=192, kernel_size=(1, 7), strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=192, out_filters=224, kernel_size=(7, 1), strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=224, out_filters=224, kernel_size=(1, 7), strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=224, out_filters=256, kernel_size=(7, 1), strides=1, padding=\"same\"),\n",
        "        )\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_1 = self.avg_block(x)\n",
        "        x_2 = self.one_by_one_block(x)\n",
        "        x_3 = self.seven_by_seven_block(x)\n",
        "        x_4 = self.thirteen_by_thirteen_block(x)\n",
        "        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "c66MoXK68rgh"
      },
      "outputs": [],
      "source": [
        "class C_block(Module):\n",
        "\n",
        "    def __init__(self, in_filters):\n",
        "        super().__init__()\n",
        "        self.avg_block = Sequential(\n",
        "            AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=256, kernel_size=1, strides=1, padding=\"same\"),\n",
        "        )\n",
        "        self.one_by_one_block = Conv2d_bn(in_filters=in_filters, out_filters=256, kernel_size=1, strides=1, padding=\"same\")\n",
        "\n",
        "        self.branch_a =  Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=1, strides=1, padding=\"same\")\n",
        "        self.branch_a_left = Conv2d_bn(in_filters=384, out_filters=256, kernel_size=(1, 3), strides=1, padding=\"same\")\n",
        "        self.branch_a_right = Conv2d_bn(in_filters=384, out_filters=256, kernel_size=(3, 1), strides=1, padding=\"same\")\n",
        "\n",
        "        self.branch_b =  Sequential(\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=1, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=384, out_filters=448, kernel_size=(1, 3), strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=448, out_filters=512, kernel_size=(3, 1), strides=1, padding=\"same\"),\n",
        "        )\n",
        "\n",
        "        self.branch_b_left = Conv2d_bn(in_filters=512, out_filters=256, kernel_size=(1, 3), strides=1, padding=\"same\")\n",
        "        self.branch_b_right = Conv2d_bn(in_filters=512, out_filters=256, kernel_size=(3, 1), strides=1, padding=\"same\")\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_1 = self.avg_block(x)\n",
        "        x_2 = self.one_by_one_block(x)\n",
        "        x_a = self.branch_a(x)\n",
        "        x_3 = self.branch_a_left(x_a)\n",
        "        x_4 = self.branch_a_right(x_a)\n",
        "        x_b = self.branch_b(x)\n",
        "        x_5 = self.branch_b_left(x_b)\n",
        "        x_6 = self.branch_b_right(x_b)\n",
        "        x = torch.cat([x_1, x_2, x_3, x_4, x_5, x_6], axis=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "k_VRXueZ8rgi"
      },
      "outputs": [],
      "source": [
        "class Reduction_A(Module):\n",
        "\n",
        "    def __init__(self, in_filters):\n",
        "        super().__init__()\n",
        "        self.max_pool = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "        self.central_block = Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=3, strides=2, padding=\"valid\")\n",
        "        self.right_block =  Sequential(\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=192, out_filters=224, kernel_size=3, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=224, out_filters=256, kernel_size=3, strides=2, padding=\"valid\"),\n",
        "        )\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_1 = self.max_pool(x)\n",
        "        x_2 = self.central_block(x)\n",
        "        x_3 = self.right_block(x)\n",
        "        x = torch.cat([x_1, x_2, x_3], axis=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OQTlU3UI8rgj"
      },
      "outputs": [],
      "source": [
        "class Reduction_B(Module):\n",
        "\n",
        "    def __init__(self, in_filters):\n",
        "        super().__init__()\n",
        "        self.max_pool = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "        self.central_block = Sequential(\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=192, out_filters=192, kernel_size=3, strides=2, padding=\"valid\"),\n",
        "        )\n",
        "        self.right_block =  Sequential(\n",
        "            Conv2d_bn(in_filters=in_filters, out_filters=256, kernel_size=1, strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=256, out_filters=256, kernel_size=(1, 7), strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=256, out_filters=320, kernel_size=(7, 1), strides=1, padding=\"same\"),\n",
        "            Conv2d_bn(in_filters=320, out_filters=320, kernel_size=3, strides=2, padding=\"valid\"),\n",
        "        )\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_1 = self.max_pool(x)\n",
        "        x_2 = self.central_block(x)\n",
        "        x_3 = self.right_block(x)\n",
        "        x = torch.cat([x_1, x_2, x_3], axis=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hvjCcTe78rgk"
      },
      "outputs": [],
      "source": [
        "class InceptionV4(Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.stem = StemBlock()\n",
        "        self.inception_a = Sequential(\n",
        "            A_block(384),\n",
        "            A_block(384),\n",
        "            A_block(384),\n",
        "            A_block(384)\n",
        "        )\n",
        "        self.reduction_a = Reduction_A(384)\n",
        "        self.inception_b = Sequential(\n",
        "            B_block(1024),\n",
        "            B_block(1024),\n",
        "            B_block(1024),\n",
        "            B_block(1024),\n",
        "            B_block(1024),\n",
        "            B_block(1024),\n",
        "            B_block(1024)\n",
        "        )\n",
        "        self.reduction_b = Reduction_B(1024)\n",
        "        self.inception_c = Sequential(\n",
        "            C_block(1536),\n",
        "            C_block(1536),\n",
        "            C_block(1536)\n",
        "        )\n",
        "        self.drop = Dropout(0.2)\n",
        "        #self.out = Linear(1536, 1)\n",
        "        self.out = Linear(1536, 75)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.inception_a(x)\n",
        "        x = self.reduction_a(x)\n",
        "        x = self.inception_b(x)\n",
        "        x = self.reduction_b(x)\n",
        "        x = self.inception_c(x)\n",
        "        x = x.reshape(x.shape[0], -1, 1536).mean(axis=1)\n",
        "        x = self.drop(x)\n",
        "        y = self.out(x)\n",
        "        return y\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngE8aD4TbwaD"
      },
      "source": [
        "## Defining other Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n1uXKCc6qMnc"
      },
      "outputs": [],
      "source": [
        "def top_k_accuracy(predictions, true, k):\n",
        "    top_k_preds = predictions.topk(k, dim=1).indices\n",
        "    correct = top_k_preds.eq(true.view(-1, 1).expand_as(top_k_preds))\n",
        "    top_k_acc = correct.sum().float()/true.size(0)\n",
        "    return top_k_acc\n",
        "\n",
        "def normalize(data):\n",
        "    return (data - data.min()) /  (data.max() - data.min())\n",
        "\n",
        "def normalize_norm(data):\n",
        "    return data/np.linalg.norm(data)\n",
        "\n",
        "def normalize_range(data):\n",
        "    top = 0.01\n",
        "    btm = 0.99\n",
        "    norm_01 = normalize(data)\n",
        "\n",
        "    return norm_01*(top-btm) + btm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "oe3qlFshfBcK"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 alpha = None,          #tensor, Weights for each class\n",
        "                 gamma = 0.):           #Const\n",
        "\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "        self.cross_entropy_loss = CrossEntropyLoss(reduction = 'none')\n",
        "\n",
        "    def forward(self, x, y):\n",
        "\n",
        "        ce = self.cross_entropy_loss(x, y)\n",
        "        pt = torch.exp(-ce)\n",
        "        focal_loss = self.alpha[y] * (1 - pt) ** self.gamma * ce\n",
        "\n",
        "        focal_loss = focal_loss.mean()\n",
        "\n",
        "        return focal_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP-rzZOhEXKh",
        "outputId": "ae04bfbe-a0f3-4193-9829-5ae13fe228c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "59.55098894569825 [0.91102173 0.94832192 0.9347254  0.95561455 0.87721128 0.88487893\n",
            " 0.96405707 0.23811528 0.71197795 0.92157353 0.78124691 0.82354389\n",
            " 0.95670254 0.98115747 0.86308867 0.44933314 0.95315555 0.778833\n",
            " 0.82952528 0.95346542 0.97660589 0.8487269  0.76591143 0.41702923\n",
            " 0.20769991 0.94660983 0.78124691 0.85728534 0.99       0.96565905\n",
            " 0.94660983 0.98277165 0.98768447 0.01       0.98647402 0.91780572\n",
            " 0.50424978 0.68959345 0.0998636  0.13893473 0.92275247 0.82198179\n",
            " 0.96453051 0.97482293 0.96306947 0.97746766 0.87795084 0.95315555\n",
            " 0.13893473 0.95839816 0.9812332  0.94882622 0.96968034 0.53873233\n",
            " 0.65165761 0.33949986 0.97181942 0.33949986 0.95377108 0.9382252\n",
            " 0.33949986 0.91102173 0.44933314 0.97653291 0.95616554 0.53873233\n",
            " 0.96306947 0.94895072 0.96357025 0.77636483 0.9780971  0.97045703\n",
            " 0.96907994 0.91254308 0.97325054]\n"
          ]
        }
      ],
      "source": [
        "classCount_train = np.array([118, 201, 161, 236, 83, 92, 296, 14, 36, 135, 49, 59, 248, 592, 76, 19, 224, 47, 60, 226, 465, 69, 44, 19, 14, 199, 47, 71, 1201, 319, 195, 643, 937, 10, 845, 127, 22, 34, 13, 13, 133, 57, 299, 431, 288, 490, 84, 226, 14, 253, 587, 208, 360, 22, 30, 16, 381, 16, 228, 168, 17, 120, 20, 469, 241, 22, 288, 208, 299, 47, 498, 360, 350, 120, 407])\n",
        "classCount_val = np.array([48, 86, 82, 103, 44, 50, 135, 5, 22, 64, 26, 25, 108, 266, 32, 6, 115, 27, 37, 96, 228, 31, 20, 6, 4, 86, 25, 33, 570, 119, 99, 293, 439, 3, 405, 54, 11, 11, 4, 5, 70, 34, 134, 208, 128, 217, 45, 95, 3, 111, 300, 110, 145, 5, 11, 8, 195, 10, 104, 71, 7, 54, 7, 219, 121, 11, 142, 94, 130, 18, 252, 185, 156, 49, 197])\n",
        "classCount_test = np.array([60, 107, 67, 122, 36, 32, 143, 7, 11, 58, 16, 29, 117, 282, 38, 11, 97, 16, 20, 117, 210, 32, 21, 9, 7, 96, 19, 36, 555, 164, 87, 321, 452, 7, 394, 64, 7, 19, 5, 5, 58, 21, 149, 196, 142, 233, 35, 115, 6, 129, 258, 80, 181, 16, 16, 6, 165, 4, 110, 89, 6, 52, 9, 212, 105, 10, 128, 97, 137, 24, 219, 160, 166, 61, 179])\n",
        "\n",
        "classCountAll = classCount_train + classCount_val + classCount_test\n",
        "\n",
        "invClassFrequency = sum(classCountAll) / (len(classCountAll)*classCountAll)\n",
        "invClassFrequency = normalize_range(invClassFrequency)\n",
        "print(sum(invClassFrequency), invClassFrequency)\n",
        "weights = (torch.from_numpy(invClassFrequency))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwqFfobrcCwS"
      },
      "source": [
        "## Training the Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f51UH-r98rgm",
        "outputId": "b903eda9-855d-4d1e-f57a-dce12f952eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train loss: 2.999082589253817: 100%|██████████| 251/251 [00:41<00:00,  6.12it/s]\n",
            "100%|██████████| 117/117 [00:06<00:00, 18.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 3.2933170054106715, accuracy: 0.07604765892028809,\n",
            " top 5 acc: 0.2857142686843872, top 10 acc: 0.439148485660553\n",
            "Saved Model\n",
            "Epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train loss: 3.01764517437692: 100%|██████████| 251/251 [00:38<00:00,  6.51it/s]\n",
            "100%|██████████| 117/117 [00:06<00:00, 19.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 3.240254949387132, accuracy: 0.07591377198696136,\n",
            " top 5 acc: 0.2945508062839508, top 10 acc: 0.4467800259590149\n",
            "Saved Model\n",
            "Epoch: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train loss: 3.053889787242613: 100%|██████████| 251/251 [00:38<00:00,  6.47it/s]\n",
            "100%|██████████| 117/117 [00:06<00:00, 18.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 3.1853808237089085, accuracy: 0.08863301575183868,\n",
            " top 5 acc: 0.3033873438835144, top 10 acc: 0.47235238552093506\n",
            "Saved Model\n",
            "Epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train loss: 3.077823596449015: 100%|██████████| 251/251 [00:38<00:00,  6.49it/s]\n",
            "100%|██████████| 117/117 [00:06<00:00, 18.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 3.081217702013372, accuracy: 0.09921006858348846,\n",
            " top 5 acc: 0.33190521597862244, top 10 acc: 0.4944436848163605\n",
            "Saved Model\n",
            "Epoch: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train loss: 3.356872961529821: 100%|██████████| 251/251 [00:38<00:00,  6.48it/s]\n",
            "100%|██████████| 117/117 [00:06<00:00, 19.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 3.0564423345726275, accuracy: 0.09331905096769333,\n",
            " top 5 acc: 0.33324405550956726, top 10 acc: 0.5015397071838379\n",
            "Saved Model\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "weights = weights.to(device)\n",
        "\n",
        "model = InceptionV4()\n",
        "#opt = SGD(model.parameters(), lr=0.005)\n",
        "opt = Adam(model.parameters(), lr=0.001)\n",
        "#loss_fn = CrossEntropyLoss()\n",
        "loss_fn = FocalLoss(alpha = weights, gamma = 2)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "epochs = 5\n",
        "best_val = np.inf\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    train_dataset = ImageDataset(\"/content/Car-make-classification/data/resized_images\", \"train\", transforms)\n",
        "\n",
        "\n",
        "    test_dataset = ImageDataset(\"/content/Car-make-classification/data/resized_images\", \"test\", ToTensor())\n",
        "\n",
        "\n",
        "    valid_dataset = ImageDataset(\"/content/Car-make-classification/data/resized_images\", \"validation\", ToTensor())\n",
        "\n",
        "    batch_size = 64\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())\n",
        "    valid_dataloader = DataLoader(valid_dataset, batch_size, shuffle=False, num_workers=os.cpu_count())\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=os.cpu_count())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        print(f\"Epoch: {epoch+1}\")\n",
        "        iterator = tqdm(train_dataloader)\n",
        "        for batch_x, batch_y in iterator:\n",
        "\n",
        "            batch_x = batch_x.to(device)\n",
        "            batch_y = batch_y.to(device)\n",
        "\n",
        "            y_pred = model(batch_x)\n",
        "\n",
        "            loss = loss_fn(y_pred, batch_y)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            iterator.set_description(f\"Train loss: {loss.detach().cpu().numpy()}\")\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            predictions = []\n",
        "            true = []\n",
        "            for batch_x, batch_y in tqdm(valid_dataloader):\n",
        "                batch_x = batch_x.to(device)\n",
        "                batch_y = batch_y.to(device)\n",
        "\n",
        "                y_pred = model(batch_x)\n",
        "\n",
        "                predictions.append(y_pred)\n",
        "                true.append(batch_y)\n",
        "            predictions = torch.cat(predictions, axis=0)\n",
        "            true = torch.cat(true, axis=0)\n",
        "            val_loss = loss_fn(predictions, true)\n",
        "\n",
        "            val_acc = (predictions.argmax(dim=1) == true).float().mean()  # Use argmax for multi-class accuracy\n",
        "            val_acc_top_5 = top_k_accuracy(predictions, true, 5)\n",
        "            val_acc_top_10 = top_k_accuracy(predictions, true, 10)\n",
        "\n",
        "            print(f\"loss: {val_loss}, accuracy: {val_acc},\\n top 5 acc: {val_acc_top_5}, top 10 acc: {val_acc_top_10}\")\n",
        "\n",
        "        if val_loss < best_val:\n",
        "            print(\"Saved Model\")\n",
        "            torch.save(model.state_dict(), \"model_FL.pt\")\n",
        "            best_val = val_loss"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
