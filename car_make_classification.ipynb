{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "from torchvision.transforms import Compose, ToTensor, RandomAffine, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "from dataset import ImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Securing reproducability\n",
    "seed = 0\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = Compose([\n",
    "    ToTensor(), #this converts numpy or Pil image to torch tensor and normalizes it in 0, 1\n",
    "    #RandomAffine((0.05, 0.05)),\n",
    "    #RandomHorizontalFlip(),\n",
    "    #RandomVerticalFlip()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class ImageDataset(Dataset):\n",
    "\n",
    "#     def __init__(self, dataset_folder, dataset_type, transform=None):\n",
    "#         self.dataset_folder = os.path.join(dataset_folder, dataset_type)\n",
    "#         self.x = [f for f in os.listdir(self.dataset_folder) if f.endswith('.jpg')]\n",
    "#         self.transform = transform\n",
    "\n",
    "\n",
    "#     def __len__(self):\n",
    "#         #return min(100, len(self.x))\n",
    "#         return len(self.x)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         x = self.x[idx]\n",
    "#         y = self.y[idx, 0, 0].astype(float)\n",
    "#         if self.transform:\n",
    "#             x = self.transform(x)\n",
    "#         return x, y\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         img_name = self.x[idx]\n",
    "#         img_path = os.path.join(self.dataset_folder, img_name)\n",
    "#         image = Image.open(img_path)\n",
    "#         label = int(img_name.split('_')[0])\n",
    "        \n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "        \n",
    "#         return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = ImageDataset(\"./data/resized_images\", \"train\", ToTensor())\n",
    "# print(\"Train dataset at index 5: \", train_dataset[5])\n",
    "# print('Length train: ', len(train_dataset))\n",
    "\n",
    "# test_dataset = ImageDataset(\"./data/resized_images\", \"test\", ToTensor())\n",
    "# print('Length test: ', len(test_dataset))\n",
    "\n",
    "# valid_dataset = ImageDataset(\"./data/resized_images\", \"validation\", ToTensor())\n",
    "# print('Length validation: ', len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig, axs = plt.subplots(4, 4, figsize=(6,6))\n",
    "# for i in range(16):\n",
    "#     axs[i//4][i%4].imshow(train_dataset[i][0].permute(1, 2, 0).numpy())\n",
    "#     axs[i//4][i%4].set_xticks([])\n",
    "#     axs[i//4][i%4].set_yticks([])\n",
    "#     axs[i//4][i%4].set_title(f\"class: {train_dataset[i][1]}\")\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 64\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "# valid_dataloader = DataLoader(valid_dataset, batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "from torch.nn import Module, Sequential, Conv2d, BatchNorm2d, ReLU\n",
    "from torch.nn import MaxPool2d, AvgPool2d, Linear, Dropout\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d_bn(Module):\n",
    "    def __init__(self, in_filters, out_filters, kernel_size, strides, padding):\n",
    "        super().__init__()\n",
    "        if isinstance(kernel_size, tuple):\n",
    "            padding_val = (k // 2 for k in kernel_size) if padding == \"same\" else (0,0)\n",
    "        else:\n",
    "            padding_val = kernel_size // 2 if padding == \"same\" else 0\n",
    "        self.conv = Conv2d(in_filters, out_filters, kernel_size=kernel_size, stride=strides, padding=padding_val)\n",
    "        self.bn = BatchNorm2d(out_filters)\n",
    "        self.relu = ReLU()\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemBlock(Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_block = Sequential(\n",
    "            Conv2d_bn(in_filters=3, out_filters=32, kernel_size=3, strides=2, padding=\"valid\"),\n",
    "            Conv2d_bn(in_filters=32, out_filters=32, kernel_size=3, strides=1, padding=\"valid\"),\n",
    "            Conv2d_bn(in_filters=32, out_filters=64, kernel_size=3, strides=1, padding=\"same\"),\n",
    "        )\n",
    "        self.first_left = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.first_right = Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=2, padding=\"valid\")\n",
    "        self.second_left =  Sequential(\n",
    "            Conv2d_bn(in_filters=160, out_filters=64, kernel_size=1, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding=\"valid\"),\n",
    "        )\n",
    "        self.second_right =  Sequential(\n",
    "            Conv2d_bn(in_filters=160, out_filters=64, kernel_size=1, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=64, out_filters=64, kernel_size=(7, 1), strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=64, out_filters=64, kernel_size=(1, 7), strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding=\"valid\"),\n",
    "        )\n",
    "        self.third_left = Conv2d_bn(in_filters=192, out_filters=192, kernel_size=3, strides=2, padding=\"valid\")\n",
    "        self.third_right = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_block(x)\n",
    "        x_l = self.first_left(x)\n",
    "        x_r = self.first_right(x)\n",
    "        x = torch.cat([x_l, x_r], axis=1)\n",
    "        x_l = self.second_left(x)\n",
    "        x_r = self.second_right(x)\n",
    "        x = torch.cat([x_l, x_r], axis=1)\n",
    "        x_l = self.third_left(x)\n",
    "        x_r = self.third_right(x)\n",
    "        x = torch.cat([x_l, x_r], axis=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A_block(Module):\n",
    "\n",
    "    def __init__(self, in_filters):\n",
    "        super().__init__()\n",
    "        self.avg_block = Sequential(\n",
    "            AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=96, kernel_size=1, strides=1, padding=\"same\"),\n",
    "        )\n",
    "        self.one_by_one_block = Conv2d_bn(in_filters=in_filters, out_filters=96, kernel_size=1, strides=1, padding=\"same\")\n",
    "        self.three_by_three_block =  Sequential(\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=64, kernel_size=1, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding=\"same\"),\n",
    "        )\n",
    "        self.five_by_five =  Sequential(\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=64, kernel_size=1, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=96, out_filters=96, kernel_size=3, strides=1, padding=\"same\"),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "    def forward(self, x):\n",
    "        x_1 = self.avg_block(x)\n",
    "        x_2 = self.one_by_one_block(x)\n",
    "        x_3 = self.three_by_three_block(x)\n",
    "        x_4 = self.five_by_five(x)\n",
    "        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B_block(Module):\n",
    "\n",
    "    def __init__(self, in_filters):\n",
    "        super().__init__()\n",
    "        self.avg_block = Sequential(\n",
    "            AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=128, kernel_size=1, strides=1, padding=\"same\"),\n",
    "        )\n",
    "        self.one_by_one_block = Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=1, strides=1, padding=\"same\")\n",
    "\n",
    "        self.seven_by_seven_block =  Sequential(\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=192, out_filters=224, kernel_size=(1, 7), strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=224, out_filters=256, kernel_size=(7, 1), strides=1, padding=\"same\"),\n",
    "        )\n",
    "\n",
    "        self.thirteen_by_thirteen_block =  Sequential(\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=192, out_filters=192, kernel_size=(1, 7), strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=192, out_filters=224, kernel_size=(7, 1), strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=224, out_filters=224, kernel_size=(1, 7), strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=224, out_filters=256, kernel_size=(7, 1), strides=1, padding=\"same\"),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.avg_block(x)\n",
    "        x_2 = self.one_by_one_block(x)\n",
    "        x_3 = self.seven_by_seven_block(x)\n",
    "        x_4 = self.thirteen_by_thirteen_block(x)\n",
    "        x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C_block(Module):\n",
    "\n",
    "    def __init__(self, in_filters):\n",
    "        super().__init__()\n",
    "        self.avg_block = Sequential(\n",
    "            AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=256, kernel_size=1, strides=1, padding=\"same\"),\n",
    "        )\n",
    "        self.one_by_one_block = Conv2d_bn(in_filters=in_filters, out_filters=256, kernel_size=1, strides=1, padding=\"same\")\n",
    "\n",
    "        self.branch_a =  Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=1, strides=1, padding=\"same\")\n",
    "        self.branch_a_left = Conv2d_bn(in_filters=384, out_filters=256, kernel_size=(1, 3), strides=1, padding=\"same\")\n",
    "        self.branch_a_right = Conv2d_bn(in_filters=384, out_filters=256, kernel_size=(3, 1), strides=1, padding=\"same\")\n",
    "\n",
    "        self.branch_b =  Sequential(\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=1, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=384, out_filters=448, kernel_size=(1, 3), strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=448, out_filters=512, kernel_size=(3, 1), strides=1, padding=\"same\"),\n",
    "        )\n",
    "\n",
    "        self.branch_b_left = Conv2d_bn(in_filters=512, out_filters=256, kernel_size=(1, 3), strides=1, padding=\"same\")\n",
    "        self.branch_b_right = Conv2d_bn(in_filters=512, out_filters=256, kernel_size=(3, 1), strides=1, padding=\"same\")\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.avg_block(x)\n",
    "        x_2 = self.one_by_one_block(x)\n",
    "        x_a = self.branch_a(x)\n",
    "        x_3 = self.branch_a_left(x_a)\n",
    "        x_4 = self.branch_a_right(x_a)\n",
    "        x_b = self.branch_b(x)\n",
    "        x_5 = self.branch_b_left(x_b)\n",
    "        x_6 = self.branch_b_right(x_b)\n",
    "        x = torch.cat([x_1, x_2, x_3, x_4, x_5, x_6], axis=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reduction_A(Module):\n",
    "\n",
    "    def __init__(self, in_filters):\n",
    "        super().__init__()\n",
    "        self.max_pool = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.central_block = Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=3, strides=2, padding=\"valid\")\n",
    "        self.right_block =  Sequential(\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=192, out_filters=224, kernel_size=3, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=224, out_filters=256, kernel_size=3, strides=2, padding=\"valid\"),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.max_pool(x)\n",
    "        x_2 = self.central_block(x)\n",
    "        x_3 = self.right_block(x)\n",
    "        x = torch.cat([x_1, x_2, x_3], axis=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reduction_B(Module):\n",
    "\n",
    "    def __init__(self, in_filters):\n",
    "        super().__init__()\n",
    "        self.max_pool = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
    "        self.central_block = Sequential(\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=192, out_filters=192, kernel_size=3, strides=2, padding=\"valid\"),\n",
    "        )\n",
    "        self.right_block =  Sequential(\n",
    "            Conv2d_bn(in_filters=in_filters, out_filters=256, kernel_size=1, strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=256, out_filters=256, kernel_size=(1, 7), strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=256, out_filters=320, kernel_size=(7, 1), strides=1, padding=\"same\"),\n",
    "            Conv2d_bn(in_filters=320, out_filters=320, kernel_size=3, strides=2, padding=\"valid\"),\n",
    "        )\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_1 = self.max_pool(x)\n",
    "        x_2 = self.central_block(x)\n",
    "        x_3 = self.right_block(x)\n",
    "        x = torch.cat([x_1, x_2, x_3], axis=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionV4(Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stem = StemBlock()\n",
    "        self.inception_a = Sequential(\n",
    "            A_block(384),\n",
    "            A_block(384),\n",
    "            A_block(384),\n",
    "            A_block(384)\n",
    "        )\n",
    "        self.reduction_a = Reduction_A(384)\n",
    "        self.inception_b = Sequential(\n",
    "            B_block(1024),\n",
    "            B_block(1024),\n",
    "            B_block(1024),\n",
    "            B_block(1024),\n",
    "            B_block(1024),\n",
    "            B_block(1024),\n",
    "            B_block(1024)\n",
    "        )\n",
    "        self.reduction_b = Reduction_B(1024)\n",
    "        self.inception_c = Sequential(\n",
    "            C_block(1536),\n",
    "            C_block(1536),\n",
    "            C_block(1536)\n",
    "        )\n",
    "        self.drop = Dropout(0.2)\n",
    "        #self.out = Linear(1536, 1)\n",
    "        self.out = Linear(1536, 75)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.inception_a(x)\n",
    "        x = self.reduction_a(x)\n",
    "        x = self.inception_b(x)\n",
    "        x = self.reduction_b(x)\n",
    "        x = self.inception_c(x)\n",
    "        x = x.reshape(x.shape[0], -1, 1536).mean(axis=1)\n",
    "        x = self.drop(x)\n",
    "        y = self.out(x)\n",
    "        return y\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            torch.nn.init.xavier_uniform_(module.weight)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 75])\n",
      "Expected shape (1, 1)\n"
     ]
    }
   ],
   "source": [
    "inception_v4 = InceptionV4()\n",
    "print(inception_v4(torch.zeros(1, 3, 299, 299)).shape)\n",
    "print(\"Expected shape (1, 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train loss: 4.6345648765563965:  10%|â–‰         | 24/251 [02:04<19:18,  5.10s/it]"
     ]
    }
   ],
   "source": [
    "model = InceptionV4()\n",
    "opt = SGD(model.parameters(), lr=0.005)\n",
    "#loss_fn = BCEWithLogitsLoss()\n",
    "loss_fn = CrossEntropyLoss()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "epochs=10\n",
    "best_val = np.inf\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    train_dataset = ImageDataset(\"./data/resized_images\", \"train\", ToTensor())\n",
    "\n",
    "\n",
    "    test_dataset = ImageDataset(\"./data/resized_images\", \"test\", ToTensor())\n",
    "\n",
    "\n",
    "    valid_dataset = ImageDataset(\"./data/resized_images\", \"validation\", ToTensor())\n",
    "\n",
    "    batch_size = 64\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        print(f\"Epoch: {epoch+1}\")\n",
    "        iterator = tqdm(train_dataloader)\n",
    "        for batch_x, batch_y in iterator:\n",
    "            # print(len(batch_y))\n",
    "            # print(batch_x, batch_y)\n",
    "            # print(\"Size of batch_x:\", batch_x.size())\n",
    "            batch_x = batch_x.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            y_pred = model(batch_x)\n",
    "\n",
    "            loss = loss_fn(y_pred, batch_y)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            iterator.set_description(f\"Train loss: {loss.detach().cpu().numpy()}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            true = []\n",
    "            for batch_x, batch_y in tqdm(valid_dataloader):\n",
    "                batch_x = batch_x.to(device)\n",
    "                batch_y = batch_y.to(device)\n",
    "\n",
    "                y_pred = model(batch_x)\n",
    "\n",
    "                predictions.append(y_pred)\n",
    "                true.append(batch_y)\n",
    "            predictions = torch.cat(predictions, axis=0)\n",
    "            true = torch.cat(true, axis=0)\n",
    "            val_loss = loss_fn(predictions, true)\n",
    "            #val_acc = (torch.sigmoid(predictions).round() == true).float().mean()\n",
    "            val_acc = (predictions.argmax(dim=1) == true).float().mean()  # Use argmax for multi-class accuracy\n",
    "\n",
    "            print(f\"loss: {val_loss}, accuracy: {val_acc}\")\n",
    "\n",
    "        if val_loss < best_val:\n",
    "            print(\"Saved Model\")\n",
    "            torch.save(model.state_dict(), \"model.pt\")\n",
    "            best_val = val_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
